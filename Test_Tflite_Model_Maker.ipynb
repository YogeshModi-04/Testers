{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "label_dict = {\n",
    "    0: \"\",\n",
    "    1: \"\",\n",
    "    2: \"\",\n",
    "    3: \"\",\n",
    "    4: \"\",\n",
    "    5: \"\",\n",
    "}\n",
    "'''\n",
    "count = 0\n",
    "file = open('labelmap.txt')\n",
    "for line in file:\n",
    "    label_dict[count]=line\n",
    "    count += 1\n",
    "print(\"hello\",label_dict)'''\n",
    "# Define a list of colors for visualization\n",
    "COLORS = np.random.randint(0, 255, size=(12, 3), dtype=np.uint8)\n",
    "\n",
    "def preprocess_image(image, input_size):\n",
    "  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\n",
    "#   img = tf.io.read_file(image_path)\n",
    "#   img = tf.io.decode_image(img, channels=3)\n",
    "  img = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "  original_image = img\n",
    "  resized_img = tf.image.resize(img, input_size)\n",
    "  resized_img = resized_img[tf.newaxis, :]\n",
    "  resized_img = tf.cast(resized_img, dtype=tf.uint8)\n",
    "  return resized_img, original_image\n",
    "\n",
    "\n",
    "def detect_objects(interpreter, image, threshold):\n",
    "    \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n",
    "\n",
    "    signature_fn = interpreter.get_signature_runner()\n",
    "\n",
    "    # Feed the input image to the model\n",
    "    output = signature_fn(images=image)\n",
    "    print(output)\n",
    "    # Get all outputs from the model\n",
    "    count = int(np.squeeze(output['output_0']))\n",
    "    scores = np.squeeze(output['output_1'])\n",
    "    classes = np.squeeze(output['output_2'])\n",
    "    boxes = np.squeeze(output['output_3'])\n",
    "    \n",
    "    results = []\n",
    "    for i in range(count):\n",
    "        if scores[i] * 100 >= threshold:\n",
    "            class_id = int(classes[i])  # Convert the class ID to an integer\n",
    "            if class_id in label_dict:\n",
    "                result = {\n",
    "                    'bounding_box': boxes[i],\n",
    "                    'class_id': class_id,\n",
    "                    'score': scores[i]\n",
    "                }\n",
    "                print(result)\n",
    "                results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_odt_and_draw_results(image_path, interpreter, threshold=10):\n",
    "    \"\"\"Run object detection on the input image and draw the detection results\"\"\"\n",
    "    # Load the input shape required by the model\n",
    "    _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
    "\n",
    "    # Load the input image and preprocess it\n",
    "    preprocessed_image, original_image = preprocess_image(\n",
    "        image_path,\n",
    "        (input_height, input_width)\n",
    "        )\n",
    "\n",
    "    # Run object detection on the input image\n",
    "    results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\n",
    "    # Plot the detection results on the input image\n",
    "    original_image_np = original_image.numpy().astype(np.uint8)\n",
    "    for obj in results:\n",
    "        # Convert the object bounding box from relative coordinates to absolute\n",
    "        # coordinates based on the original image resolution\n",
    "        ymin, xmin, ymax, xmax = obj['bounding_box']\n",
    "        xmin = int(xmin * original_image_np.shape[1])\n",
    "        xmax = int(xmax * original_image_np.shape[1])\n",
    "        ymin = int(ymin * original_image_np.shape[0])\n",
    "        ymax = int(ymax * original_image_np.shape[0])\n",
    "\n",
    "        # Find the class index of the current object\n",
    "        class_id = int(obj['class_id'])\n",
    "        # Draw the bounding box and label on the image\n",
    "        color = [int(c) for c in COLORS[class_id]]\n",
    "        cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "        # Make adjustments to make the label visible for all objects\n",
    "        y = ymin - 15 if ymin - 15 > 15 else ymin + 15\n",
    "        label = \"{}: {:.0f}%\".format(label_dict[class_id], obj['score'] * 100)\n",
    "        cv2.putText(original_image_np, label, (xmin, y),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Return the final image\n",
    "    original_uint8 = original_image_np.astype(np.uint8)\n",
    "    return original_uint8\n",
    "\n",
    "def run_model(image,model,DETECTION_THRESHOLD):\n",
    "    interpreter = tf.lite.Interpreter(model_path=model)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Run inference and draw detection result on the local copy of the original file\n",
    "    detection_result_image = run_odt_and_draw_results(\n",
    "        image,\n",
    "        interpreter,\n",
    "        threshold=DETECTION_THRESHOLD\n",
    "    )\n",
    "    return detection_result_image\n",
    "\n",
    "def showImage(image):        \n",
    "    cv2.imshow('Object detection', image)\n",
    "\n",
    "def testingModel(model):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "        detection_image = run_model(image,model,25)\n",
    "        cv2.imwrite(\"test.jpg\", detection_image)\n",
    "        showImage(detection_image)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "        # break\n",
    "    cap.release()\n",
    "\n",
    "testingModel('efficient3lite.tflite')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
