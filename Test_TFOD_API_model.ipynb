{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.lite.python.interpreter import Interpreter\n",
    "\n",
    "input_mean = 127.5\n",
    "input_std = 127.5\n",
    "\n",
    "# Set up variables for running user's model\n",
    "PATH_TO_MODEL=r'/media/sunbots/NewVolume/currency model/lite_model/6testmodel.tflite'   # Path to .tflite model file\n",
    "PATH_TO_LABELS='/media/sunbots/NewVolume/labelmap.txt'   # Path to labelmap.txt file\n",
    "min_conf_threshold=0.65   # Confidence threshold (try changing this to 0.01 if you don't see any detection results)\n",
    "# Load the label map into memory\n",
    "with open(PATH_TO_LABELS, 'r') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Load the Tensorflow Lite model into memory\n",
    "interpreter = Interpreter(model_path=PATH_TO_MODEL)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get model details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]\n",
    "\n",
    "float_input = (input_details[0]['dtype'] == np.float32)\n",
    "\n",
    "# Open the webcam\n",
    "#url = 'rtsp://'\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Resize the frame to the expected shape [1xHxWx3]\n",
    "    image_resized = cv2.resize(frame, (width, height))\n",
    "    image_rgb = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)\n",
    "    input_data = np.expand_dims(image_rgb, axis=0)\n",
    "\n",
    "    # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n",
    "    if float_input:\n",
    "        input_data = (np.float32(input_data) - input_mean) / input_std\n",
    "\n",
    "    # Perform the actual detection by running the model with the image as input\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Retrieve detection results\n",
    "    boxes = interpreter.get_tensor(output_details[1]['index'])[0]  # Bounding box coordinates of detected objects\n",
    "    classes = interpreter.get_tensor(output_details[3]['index'])[0]  # Class index of detected objects\n",
    "    scores = interpreter.get_tensor(output_details[0]['index'])[0]  # Confidence of detected objects\n",
    "\n",
    "    # Loop over all detections and draw detection box if confidence is above minimum threshold\n",
    "    for i in range(len(scores)):\n",
    "        if ((scores[i] > min_conf_threshold) and (scores[i] <= 1.0)):\n",
    "            # Get bounding box coordinates and draw box\n",
    "            ymin = int(max(1, (boxes[i][0] * height)))\n",
    "            xmin = int(max(1, (boxes[i][1] * width)))\n",
    "            ymax = int(min(height, (boxes[i][2] * height)))\n",
    "            xmax = int(min(width, (boxes[i][3] * width)))\n",
    "\n",
    "            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (10, 255, 0), 2)\n",
    "\n",
    "            # Draw label\n",
    "            object_name = labels[int(classes[i])]  # Look up object name from \"labels\" array using class index\n",
    "            label = '%s: %d%%' % (object_name, int(scores[i] * 100))  # Example: 'person: 72%'\n",
    "            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)  # Get font size\n",
    "            label_ymin = max(ymin, labelSize[1] + 10)  # Make sure not to draw label too close to the top of the window\n",
    "            cv2.rectangle(frame, (xmin, label_ymin - labelSize[1] - 10),\n",
    "                          (xmin + labelSize[0], label_ymin + baseLine - 10), (255, 255, 255), cv2.FILLED)  # Draw white box to put label text in\n",
    "            cv2.putText(frame, label, (xmin, label_ymin - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0),\n",
    "                        2)  # Draw label text\n",
    "\n",
    "    # Display the frame with live detections\n",
    "    frame = cv2.resize(frame,(640,640))\n",
    "    cv2.imshow(\"Live Detection\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
